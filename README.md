# ğŸ§  ARC-2025 Solver com SageAxiom

Este repositÃ³rio contÃ©m uma tentativa honesta (e um tanto desesperada) de resolver desafios do dataset **Abstraction and Reasoning Corpus (ARC)** usando uma arquitetura neural personalizada chamada `SageAxiom`. Este modelo combina elementos de visÃ£o computacional, embeddings de linguagem via BERT e mecanismos de votaÃ§Ã£o entre mÃºltiplas instÃ¢ncias de modelos para gerar saÃ­das em tarefas de transformaÃ§Ã£o visual.

## ğŸ“¦ Estrutura do Projeto

```
â”œâ”€â”€ core.py                # DefiniÃ§Ã£o do modelo SageAxiom (onde a mÃ¡gica acontece)
â”œâ”€â”€ metrics_utils.py       # FunÃ§Ãµes para anÃ¡lise de performance e geraÃ§Ã£o de grÃ¡ficos
â”œâ”€â”€ runtime_utils.py       # FunÃ§Ãµes utilitÃ¡rias de logging, padding e temporizaÃ§Ã£o
â”œâ”€â”€ sage_dabate_loop.py    # Loop de debate entre modelos para gerar consenso
â”œâ”€â”€ neural_blocks.py       # Blocos de rede reutilizÃ¡veis (encoders, atenÃ§Ã£o, refinadores)
â”œâ”€â”€ arc-agi_test_challenges.json  # Dataset de entrada (nÃ£o incluso no repo por motivos legais)
â””â”€â”€ main.py (ou equivalente)       # Script principal de treinamento e avaliaÃ§Ã£o
```

## ğŸ§ª Como funciona?

1. **PrÃ©-processamento:** Cada par input/output das tarefas ARC Ã© convertido em tensores fixos (30x30 com one-hot para 10 classes).
2. **Treinamento:** SÃ£o treinadas mÃºltiplas instÃ¢ncias (padrÃ£o: 5) do modelo `SageAxiom`, cada uma com checkpoints, early stopping e reduÃ§Ã£o de LR adaptativa.
3. **Arquitetura:** O `SageAxiom` Ã© um monstro gentil com:

   * BERT congelado para processar prompts em linguagem natural
   * Attention over memory e mÃ³dulos de escolha baseada em hipÃ³teses
   * Refinamento por convoluÃ§Ãµes + fallback conservador
   * Um sabor suave de autoatenÃ§Ã£o e GRUs, como toda rede moderna gostaria de ser
4. **InferÃªncia por VotaÃ§Ã£o:** Cada task Ã© resolvida por um **debate** entre modelos. Se 2 ou mais concordarem com uma resposta, ela Ã© considerada "aceita". Caso contrÃ¡rio, seguimos em frente como se nada tivesse acontecido.
5. **AnÃ¡lise:** GrÃ¡ficos de treino, matriz de confusÃ£o, e estatÃ­sticas por task sÃ£o geradas no final. Ah, e tem logs. Muitos logs.

## âš™ï¸ Requisitos

* Python 3.8+
* TensorFlow 2.x
* scikit-learn
* matplotlib, seaborn
* transformers (para BERT)
* GPU, paciÃªncia, e um desejo forte de entender por que inteligÃªncia Ã© tÃ£o difÃ­cil de simular

Use um ambiente virtual, a menos que vocÃª goste de viver perigosamente.

```bash
pip install -r requirements.txt  # vocÃª vai precisar montar este arquivo, claro
```

## ğŸ ExecuÃ§Ã£o

Para treinar e avaliar o modelo:

```bash
python main.py
```

Sim, nÃ£o hÃ¡ um `main.py` explÃ­cito, mas vocÃª Ã© inteligente e conseguirÃ¡ encontrar o ponto de entrada. Provavelmente Ã© o primeiro script enorme lÃ¡ em cima.

## ğŸ“Š Resultados

* Os modelos produzem grÃ¡ficos de treinamento (`training_plot_*.png`), matrizes de confusÃ£o e relatÃ³rios por classe.
* A pontuaÃ§Ã£o final Ã© estimada em percentual de tasks resolvidas.
* ProjeÃ§Ãµes otimistas de desempenho aparecem no final, junto com as tasks mais difÃ­ceis e mais longas.

## ğŸ“ SaÃ­das

* `checkpoints/`: Modelos salvos por rodada
* `sage_model_{i}`: VersÃ£o final de cada modelo treinado
* `history_prompts/`: HistÃ³rico de debate e decisÃµes por task
* `submission.json`: Resultado final do modelo (boa sorte usando isso em qualquer lugar)

## ğŸ’¡ ObservaÃ§Ãµes

* Este projeto Ã© um tributo ao caos e Ã  esperanÃ§a de que redes neurais consigam *pensar*.
* Ele nÃ£o Ã© perfeito, nem simples, mas Ã© honesto em sua ambiÃ§Ã£o.
* Pode nÃ£o resolver o ARC... mas pelo menos tenta melhor que vocÃª.

## ğŸ“œ LicenÃ§a

MIT ou algo assim. NinguÃ©m estÃ¡ monetizando essa tristeza.
